## Where does model risk governance / model risk management (MRM) fit into deep learning lifecycle?

## ğŸ§­ 1ï¸âƒ£ First â€” What is Model Risk Governance?
**Definition (practical):**

A framework of policies, controls, validation, monitoring, and oversight to ensure models are:

* Accurate

* Explainable

* Compliant

* Stable

* Fair

* Fit-for-purpose

In banking, it aligns with regulatory guidance like SR 11-7, ECB TRIM, PRA, etc.

## ğŸ“ 2ï¸âƒ£ Where It Fits in the Lifecycle

**Model risk governance** spans the entire model lifecycle, not just one stage.
## ğŸ§± Full Lifecycle With Governance Layer
```
1. Problem Definition
2. Data Collection
3. Data Preprocessing
4. Dataset Split (Train / Val / Test)
5. Model Design
6. Training (Gradient Descent runs here)
7. Validation / Tuning
8. Testing
9. Deployment
10. Monitoring
11. Retraining / Change Management

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   MODEL RISK GOVERNANCE LAYER      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   Covers ALL stages end-to-end


```
## ğŸ” 3ï¸âƒ£ Stage-Wise Mapping
### 1ï¸âƒ£ Problem Definition

#### Governance checks:

* Business justification

* Model materiality

* Risk tiering

* Regulatory impact

#### Artifacts:

* Model inventory entry

* Use case documentation

## 2ï¸âƒ£ Data Governance

### Controls on:

* Data lineage

* Data quality

* Bias assessment

### PII compliance

* Sanctions/watchlist integrity

## 3ï¸âƒ£ Model Development

*Covers:*

* Algorithm selection

* Feature engineering controls

* Explainability feasibility

* Documentation standards

*Gradient descent lives here but governance ensures:*

* Optimization is appropriate

* Loss function justified

* Convergence validated

## 4ï¸âƒ£ Training & Validation

*Governance reviews:*

* Overfitting checks

* Stability tests

* Sensitivity analysis

* Hyperparameter justification

## 5ï¸âƒ£ Independent Model Validation (IMV)

*Separate team performs:*

* Conceptual soundness review

* Mathematical verification

* Gradient/optimization review

* Reperformance testing

* They may re-run training independently.

## 6ï¸âƒ£ Testing & Benchmarking

*Validation checks:*

* Out-of-sample performance

* Challenger models

* Stress testing

* Edge cases
  
## 7ï¸âƒ£ Model Approval

* Governance bodies:*

* Model Risk Committee

* Model Validation Committee

* Approve or reject deployment.

## 8ï¸âƒ£ Deployment Controls

* Includes:*

* Version control

* Access control

* Production monitoring hooks

## 9ï¸âƒ£ Ongoing Monitoring

* Post-deployment governance monitors:*

* Data drift

* Concept drift

* Performance decay

* Bias emergence

## ğŸ”Ÿ Periodic Review / Retraining

*Triggers:*

* Performance drop

* Regulatory change

* Data shift

* Gradient descent runs again during retraining under governance oversight.

```
                 MODEL RISK GOVERNANCE
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Problem Definition        â”‚ Oversight
 Data                     â”‚ Controls
 Model Design             â”‚ Review
 Training (GD)            â”‚ Validation
 Testing                  â”‚ Challenge
 Deployment               â”‚ Approval
 Monitoring               â”‚ Surveillance
 Retraining (GD again)    â”‚ Change control
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

```
